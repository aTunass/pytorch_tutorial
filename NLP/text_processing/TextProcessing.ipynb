{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install autocorrect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vN3kRBMN0UZa",
        "outputId": "866b1a82-3163-495d-859a-325a7c00f2a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting autocorrect\n",
            "  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n",
            "\u001b[?25l\r\u001b[K     |▌                               | 10 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 25.8 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 30 kB 31.6 MB/s eta 0:00:01\r\u001b[K     |██                              | 40 kB 27.9 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 51 kB 21.5 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 61 kB 24.0 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 71 kB 25.9 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 81 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 92 kB 28.4 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 102 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 112 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 122 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 133 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 143 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████                        | 153 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 163 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 174 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 184 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 194 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 204 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 215 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 225 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 235 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 245 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 256 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 266 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 276 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 286 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 296 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 307 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 317 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 327 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 337 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 348 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 358 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 368 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 378 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 389 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 399 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 409 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 419 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 430 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 440 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 450 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 460 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 471 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 481 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 491 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 501 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 512 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 522 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 532 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 542 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 552 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 563 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 573 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 583 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 593 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 604 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 614 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 622 kB 30.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622382 sha256=dc80126aac0f48291d65ea37a09d69f3fbc07eba5493aecf9b868b0f6c88a929\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/d4/37/8244101ad50b0f7d9bffd93ce58ed7991ee1753b290923934b\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6ePIaQ1gMX-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22c8e023-1152-4401-ea97-ad7f291d9a99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "from os import remove\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import spacy\n",
        "from autocorrect import Speller\n",
        "\n",
        "class TextPreprocessor:\n",
        "    def __init__(self, stopwords=None, stemmer=None, spelling_correction=None):\n",
        "        self.stopwords = stopwords\n",
        "        self.stemmer = stemmer\n",
        "        self.spelling_correction = spelling_correction\n",
        "\n",
        "    def lowercase(self, input_str):\n",
        "        return input_str.lower()\n",
        "    \n",
        "    def uppercase(self, input_str):\n",
        "        return input_str.upper()\n",
        "\n",
        "    def remove_punct(self, input_str):\n",
        "        return input_str.translate(input_str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    def remove_stopwords(self, input_str):\n",
        "        stopwords_list = list(self.stopwords.words('english'))\n",
        "        return \" \".join([word for word in input_str.split() if word not in stopwords_list])\n",
        "        \n",
        "    def remove_freqs(self, input_str):\n",
        "        return list(set(input_str.split()))\n",
        "\n",
        "    def stem(self, input_str):\n",
        "        return \" \".join([self.stemmer.stem(word) for word in input_str.split()])\n",
        "    \n",
        "    def lemmatize(self, input_str):\n",
        "        nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "        doc = nlp(input_str)\n",
        "        return \" \".join([word.lemma_ for word in doc])\n",
        "\n",
        "    def remove_url(self, input_str):\n",
        "        return input_str.replace(\"\".join([word for word in input_str.split() if word.startswith('https://') or word.startswith('http://')]), \"\")\n",
        "\n",
        "    def remove_tags(self, input_str):\n",
        "        pattern = re.compile('<.*?>')\n",
        "        return re.sub(pattern, '', input_str)\n",
        "    \n",
        "    def word_correct(self, input_str):\n",
        "        return self.spelling_correction(input_str)\n",
        "\n",
        "    def preprocess_text(self, text, \n",
        "                        lowercase=True, \n",
        "                        uppercase=False, \n",
        "                        remove_punct=True, \n",
        "                        remove_stopwords=True, \n",
        "                        remove_freqs=False, \n",
        "                        stemming=True, \n",
        "                        lemmatize=False, \n",
        "                        remove_url=True, \n",
        "                        remove_tags=True, \n",
        "                        word_correct=True):\n",
        "        preprocessed_text = text\n",
        "\n",
        "        if lowercase == True and uppercase == True:\n",
        "            print(\"Cannot do both lowercasing and uppercasing. Please specify only one of them.\")\n",
        "            return None\n",
        "        elif lowercase == True:\n",
        "            preprocessed_text = self.lowercase(preprocessed_text)\n",
        "        elif uppercase == True:\n",
        "            preprocessed_text = self.uppercase(preprocessed_text)\n",
        "        if remove_url == True:\n",
        "            preprocessed_text = self.remove_url(preprocessed_text)\n",
        "        if remove_tags == True:\n",
        "            preprocessed_text = self.remove_tags(preprocessed_text)\n",
        "        if remove_punct == True:\n",
        "            preprocessed_text = self.remove_punct(preprocessed_text)\n",
        "        if remove_stopwords == True:\n",
        "            preprocessed_text = self.remove_stopwords(preprocessed_text)\n",
        "        if remove_freqs == True:\n",
        "            preprocessed_text = self.remove_freqs(preprocessed_text)\n",
        "        if word_correct == True:\n",
        "            preprocessed_text = self.word_correct(preprocessed_text)\n",
        "        if stemming == True and lemmatize == True:\n",
        "            print(\"Cannot do both stemming and lemmatizing. Please specify only one of them.\")\n",
        "            return None\n",
        "        elif stemming == True:\n",
        "            preprocessed_text = self.stem(preprocessed_text)\n",
        "        elif lemmatize == True:\n",
        "            preprocessed_text = self.lemmatize(preprocessed_text)\n",
        "\n",
        "        return preprocessed_text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"welcome to machine learning,\"\n",
        "preprocessor = TextPreprocessor(stopwords=stopwords, stemmer=PorterStemmer(), spelling_correction=Speller(lang='en'))"
      ],
      "metadata": {
        "id": "VVJMO5eajjQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(preprocessor.preprocess_text(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zetqLznXspIP",
        "outputId": "18434526-7900-497b-8410-4f28234ff7e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "welcom machin learn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(preprocessor.preprocess_text(text, remove_punct=False, remove_url=False, word_correct =False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSUnSi2wEsJy",
        "outputId": "f1b2cdef-23c7-45de-b9af-8bff3e266807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "welcom machin learning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(preprocessor.preprocess_text(text, lowercase=True, uppercase=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwhrUybCFEEi",
        "outputId": "c4a00ce2-397c-445b-df51-15a8d51e2008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cannot do both lowercasing and uppercasing. Please specify only one of them.\n",
            "None\n"
          ]
        }
      ]
    }
  ]
}