{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Age_Gender_pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTcubNbExV4O"
      },
      "source": [
        "# Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUr6I0w1xYKM"
      },
      "source": [
        "# General libraries\n",
        "import pandas as pd  \n",
        "import numpy as np  \n",
        "import cv2        \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets, models, utils\n",
        "from torch.utils.data import Dataset, DataLoader \n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.nn import functional as F\n",
        "from skimage import io, transform\n",
        "from torch.optim import lr_scheduler\n",
        "from skimage.transform import AffineTransform, warp"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dY_6oeH9zCne"
      },
      "source": [
        "# Loading data using Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aiI7Ii_zBC1"
      },
      "source": [
        "class MyData(Dataset):\n",
        "    def __init__(self, path_dir, test_ratio=0.2, train=True, transform=None):\n",
        "        \"\"\"\n",
        "            Input:\n",
        "                path_dir: train folder\n",
        "                test_ratio: split size\n",
        "            formart image_name: <number_id>_A<age>_G<0,1>.png\n",
        "        \"\"\"\n",
        "        list_age = []\n",
        "        list_gender = []\n",
        "        list_path = []\n",
        "        for image_name in os.listdir(path_dir):\n",
        "            age = ((image_name.split(\".\")[0]).split(\"_\")[1]).split(\"A\")[-1]\n",
        "            gender = ((image_name.split(\".\")[0]).split(\"_\")[2]).split(\"G\")[-1]\n",
        "            image_path = os.path.join(path_dir, image_name)\n",
        "            \n",
        "            list_age.append(float(age))\n",
        "            list_gender.append(int(gender))\n",
        "            list_path.append(image_path)\n",
        "        \n",
        "        # max age\n",
        "        self.max_age = max(list_age)\n",
        "\n",
        "        # normalize age\n",
        "        list_age = [age / self.max_age for age in list_age]\n",
        "\n",
        "        # #Splitting the data into train and validation set\n",
        "        X_train, X_test, y_age_train, y_age_test, y_gender_train, y_gender_test = \\\n",
        "        train_test_split(list_path, list_age, list_gender, test_size=test_ratio)\n",
        "        \n",
        "        if train:\n",
        "            self.X = X_train\n",
        "            self.age_y = y_age_train\n",
        "            self.gender_y = y_gender_train\n",
        "        else:\n",
        "            self.X = X_test\n",
        "            self.age_y = y_age_test\n",
        "            self.gender_y = y_gender_test\n",
        "        \n",
        "        # apply transformation\n",
        "        self.transform=transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image = cv2.imread(self.X[idx])\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = image.astype('float')\n",
        "        age = np.array(self.age_y[idx]).astype('float')\n",
        "        gender = np.array(self.gender_y[idx]).astype('float')\n",
        "\n",
        "        sample={'image': image, 'label_age': age, 'label_gender': gender}\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "        \n",
        "        return sample"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9faU6aHJxAl"
      },
      "source": [
        "class RGBToTensor(object):\n",
        "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "    def __call__(self, sample):\n",
        "        image, age, gender = sample['image'], sample['label_age'], sample['label_gender']\n",
        "\n",
        "        # swap color axis because\n",
        "        # numpy image: H x W x C\n",
        "        # torch image: C x H x W\n",
        "        image = torch.from_numpy(image).permute(2, 0, 1).float()\n",
        "        age = torch.from_numpy(age).float()\n",
        "        gender = torch.from_numpy(gender).float()\n",
        "\n",
        "        return {'image': image,\n",
        "                'label_age': age,\n",
        "                'label_gender': gender}"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1Fb0J6PKQKz"
      },
      "source": [
        "transformed_train_data = MyData(path_dir=\"mega_age_gender\", test_ratio=0.2, train=True, transform=transforms.Compose([RGBToTensor()]))\n",
        "transformed_test_data = MyData(path_dir=\"mega_age_gender\", test_ratio=0.2, train=False, transform=transforms.Compose([RGBToTensor()]))\n",
        "\n",
        "train_dataloader = DataLoader(transformed_train_data, batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(transformed_test_data, batch_size=32, shuffle=True)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WPtmHKxM8i_"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HcVQZatM9yH"
      },
      "source": [
        "class AgeGenderModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AgeGenderModel, self).__init__()\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Dropout(p=0.5)\n",
        "        )\n",
        "\n",
        "        self.fc_age = nn.Linear(73926, 1)  #For age class\n",
        "        self.fc_gender = nn.Linear(73926, 1)    #For gender class\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        age = self.fc_age(x)\n",
        "        gender= torch.sigmoid(self.fc_gender(x))  \n",
        "\n",
        "        return {'age': age, 'gender': gender}"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMxJt7V4SeHc"
      },
      "source": [
        "# device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sd0gfzSPSdWN"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_TXHHVpSt0t"
      },
      "source": [
        "# Setting params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT4Jz48gSwVj"
      },
      "source": [
        "#Setting model and moving to device\n",
        "model_CNN = AgeGenderModel().to(device)\n",
        "#For binary output:gender\n",
        "criterion_binary= nn.BCELoss()\n",
        "#For age output\n",
        "criterion_regression = nn.MSELoss()\n",
        "optimizer = optim.SGD(model_CNN.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "of71H0ptZfPL"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DwsySwEZgOW"
      },
      "source": [
        "def train_model(model, criterion_binary, criterion_regression, optimizer, n_epochs=25):\n",
        "    \"\"\"returns trained model\"\"\"\n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.Inf\n",
        "    for epoch in range(1, n_epochs):\n",
        "        train_loss = 0.0\n",
        "        train_loss_age = 0.0\n",
        "        train_loss_gender = 0.0\n",
        "        valid_loss = 0.0\n",
        "\n",
        "        # train the model \n",
        "        model.train()\n",
        "        for batch_idx, sample_batched in enumerate(train_dataloader):\n",
        "            # importing data and moving to GPU\n",
        "            image, label_age, label_gender = sample_batched['image'].to(device),\\\n",
        "                                             sample_batched['label_age'].to(device),\\\n",
        "                                              sample_batched['label_gender'].to(device)\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            output = model(image)\n",
        "            label_age_hat = output['age']\n",
        "            label2_gender_hat = output['gender']\n",
        "     \n",
        "            # calculate loss\n",
        "            loss_age = criterion_regression(label_age_hat, label_age)\n",
        "            loss_gender = criterion_binary(label2_gender_hat, label_gender.unsqueeze(-1))\n",
        "\n",
        "      \n",
        "            loss = loss_age + loss_gender\n",
        "            # back prop\n",
        "            loss.backward()\n",
        "            # grad\n",
        "            optimizer.step()\n",
        "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "            train_loss_age = train_loss_age + ((1 / (batch_idx + 1)) * (loss_age.data - train_loss_age))\n",
        "            train_loss_gender = train_loss_gender + ((1 / (batch_idx + 1)) * (loss_gender.data - train_loss_gender))\n",
        "\n",
        "            if batch_idx % 50 == 0:\n",
        "                print('Epoch %d, Batch %d, loss: %.6f loss_age: %.6f loss_gender: %.6f' %\n",
        "                  (epoch, batch_idx + 1, train_loss, loss_age, loss_gender))\n",
        "                \n",
        "        # validate the model #\n",
        "        model.eval()\n",
        "        for batch_idx, sample_batched in enumerate(test_dataloader):\n",
        "            image, label_age, label_gender = sample_batched['image'].to(device),\\\n",
        "                                             sample_batched['label_age'].to(device),\\\n",
        "                                              sample_batched['label_gender'].to(device)\n",
        "\n",
        "            output = model(image)\n",
        "            label_age_hat = output['age']\n",
        "            label2_gender_hat = output['gender']\n",
        "         \n",
        "            # calculate loss\n",
        "            loss_age = criterion_regression(label_age_hat, label_age)\n",
        "            loss_gender = criterion_binary(label2_gender_hat, label_gender.unsqueeze(-1))\n",
        "\n",
        "\n",
        "            loss = loss_age + loss_gender\n",
        "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
        "        \n",
        "        # print training/validation statistics \n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch, train_loss, valid_loss))\n",
        "        \n",
        "        ## TODO: save the model if validation loss has decreased\n",
        "        if valid_loss < valid_loss_min:\n",
        "            torch.save(model, 'model.pt')\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "            valid_loss_min,\n",
        "            valid_loss))\n",
        "            valid_loss_min = valid_loss\n",
        "            \n",
        "    # return trained model\n",
        "    return model"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkkqAFqraGk7",
        "outputId": "b6d572fa-10cf-45ea-9237-eb820c8ca1f8"
      },
      "source": [
        "model_conv=train_model(model_CNN, criterion_binary, criterion_regression, optimizer, n_epochs=5)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Batch 1, loss: 0.740608 loss_age: 0.048498 loss_gender: 0.692110\n",
            "Epoch 1, Batch 51, loss: 0.756001 loss_age: 0.055358 loss_gender: 0.695640\n",
            "Epoch 1, Batch 101, loss: 0.753992 loss_age: 0.059784 loss_gender: 0.691849\n",
            "Epoch 1, Batch 151, loss: 0.753774 loss_age: 0.084829 loss_gender: 0.698122\n",
            "Epoch 1, Batch 201, loss: 0.754431 loss_age: 0.072938 loss_gender: 0.695431\n",
            "Epoch 1, Batch 251, loss: 0.754496 loss_age: 0.058779 loss_gender: 0.695667\n",
            "Epoch 1, Batch 301, loss: 0.754518 loss_age: 0.046270 loss_gender: 0.699324\n",
            "Epoch 1, Batch 351, loss: 0.754341 loss_age: 0.069749 loss_gender: 0.689951\n",
            "Epoch 1, Batch 401, loss: 0.754474 loss_age: 0.079494 loss_gender: 0.692130\n",
            "Epoch 1, Batch 451, loss: 0.754727 loss_age: 0.069394 loss_gender: 0.693355\n",
            "Epoch 1, Batch 501, loss: 0.754760 loss_age: 0.061668 loss_gender: 0.688476\n",
            "Epoch 1, Batch 551, loss: 0.754833 loss_age: 0.055429 loss_gender: 0.691930\n",
            "Epoch 1, Batch 601, loss: 0.754618 loss_age: 0.073693 loss_gender: 0.684038\n",
            "Epoch 1, Batch 651, loss: 0.754461 loss_age: 0.057344 loss_gender: 0.690661\n",
            "Epoch 1, Batch 701, loss: 0.754384 loss_age: 0.039952 loss_gender: 0.694523\n",
            "Epoch 1, Batch 751, loss: 0.754335 loss_age: 0.066468 loss_gender: 0.694997\n",
            "Epoch 1, Batch 801, loss: 0.754335 loss_age: 0.052960 loss_gender: 0.698565\n",
            "Epoch 1, Batch 851, loss: 0.754320 loss_age: 0.054217 loss_gender: 0.691443\n",
            "Epoch 1, Batch 901, loss: 0.754233 loss_age: 0.056875 loss_gender: 0.690884\n",
            "Epoch 1, Batch 951, loss: 0.754098 loss_age: 0.057927 loss_gender: 0.689363\n",
            "Epoch 1, Batch 1001, loss: 0.753859 loss_age: 0.037134 loss_gender: 0.694652\n",
            "Epoch 1, Batch 1051, loss: 0.753776 loss_age: 0.063998 loss_gender: 0.698977\n",
            "Epoch 1, Batch 1101, loss: 0.753828 loss_age: 0.078830 loss_gender: 0.694732\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([27])) that is different to the input size (torch.Size([27, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([31])) that is different to the input size (torch.Size([31, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.753854 \tValidation Loss: 0.753281\n",
            "Validation loss decreased (inf --> 0.753281).  Saving model ...\n",
            "Epoch 2, Batch 1, loss: 0.793558 loss_age: 0.106713 loss_gender: 0.686845\n",
            "Epoch 2, Batch 51, loss: 0.754631 loss_age: 0.053006 loss_gender: 0.692173\n",
            "Epoch 2, Batch 101, loss: 0.752923 loss_age: 0.057439 loss_gender: 0.689309\n",
            "Epoch 2, Batch 151, loss: 0.753510 loss_age: 0.078696 loss_gender: 0.695252\n",
            "Epoch 2, Batch 201, loss: 0.753738 loss_age: 0.050277 loss_gender: 0.690306\n",
            "Epoch 2, Batch 251, loss: 0.753836 loss_age: 0.071860 loss_gender: 0.691128\n",
            "Epoch 2, Batch 301, loss: 0.754126 loss_age: 0.073477 loss_gender: 0.698241\n",
            "Epoch 2, Batch 351, loss: 0.754405 loss_age: 0.058119 loss_gender: 0.691827\n",
            "Epoch 2, Batch 401, loss: 0.754369 loss_age: 0.043771 loss_gender: 0.695935\n",
            "Epoch 2, Batch 451, loss: 0.754333 loss_age: 0.091976 loss_gender: 0.702153\n",
            "Epoch 2, Batch 501, loss: 0.754519 loss_age: 0.077331 loss_gender: 0.687849\n",
            "Epoch 2, Batch 551, loss: 0.754139 loss_age: 0.042108 loss_gender: 0.696297\n",
            "Epoch 2, Batch 601, loss: 0.753788 loss_age: 0.056383 loss_gender: 0.692289\n",
            "Epoch 2, Batch 651, loss: 0.753666 loss_age: 0.063672 loss_gender: 0.692137\n",
            "Epoch 2, Batch 701, loss: 0.753806 loss_age: 0.072387 loss_gender: 0.686092\n",
            "Epoch 2, Batch 751, loss: 0.753824 loss_age: 0.076772 loss_gender: 0.697976\n",
            "Epoch 2, Batch 801, loss: 0.753732 loss_age: 0.049917 loss_gender: 0.692363\n",
            "Epoch 2, Batch 851, loss: 0.753808 loss_age: 0.067328 loss_gender: 0.695096\n",
            "Epoch 2, Batch 901, loss: 0.753811 loss_age: 0.051812 loss_gender: 0.694630\n",
            "Epoch 2, Batch 951, loss: 0.753894 loss_age: 0.058830 loss_gender: 0.685290\n",
            "Epoch 2, Batch 1001, loss: 0.753855 loss_age: 0.050147 loss_gender: 0.695833\n",
            "Epoch 2, Batch 1051, loss: 0.753790 loss_age: 0.066941 loss_gender: 0.696692\n",
            "Epoch 2, Batch 1101, loss: 0.753854 loss_age: 0.077542 loss_gender: 0.690054\n",
            "Epoch: 2 \tTraining Loss: 0.753838 \tValidation Loss: 0.753337\n",
            "Epoch 3, Batch 1, loss: 0.730649 loss_age: 0.039485 loss_gender: 0.691163\n",
            "Epoch 3, Batch 51, loss: 0.751354 loss_age: 0.071438 loss_gender: 0.697171\n",
            "Epoch 3, Batch 101, loss: 0.753407 loss_age: 0.067171 loss_gender: 0.690795\n",
            "Epoch 3, Batch 151, loss: 0.752259 loss_age: 0.035989 loss_gender: 0.693357\n",
            "Epoch 3, Batch 201, loss: 0.752729 loss_age: 0.058157 loss_gender: 0.689373\n",
            "Epoch 3, Batch 251, loss: 0.753081 loss_age: 0.053233 loss_gender: 0.688797\n",
            "Epoch 3, Batch 301, loss: 0.753523 loss_age: 0.054101 loss_gender: 0.690197\n",
            "Epoch 3, Batch 351, loss: 0.753040 loss_age: 0.058350 loss_gender: 0.694273\n",
            "Epoch 3, Batch 401, loss: 0.753121 loss_age: 0.052172 loss_gender: 0.695493\n",
            "Epoch 3, Batch 451, loss: 0.753426 loss_age: 0.069953 loss_gender: 0.694786\n",
            "Epoch 3, Batch 501, loss: 0.753849 loss_age: 0.069449 loss_gender: 0.687022\n",
            "Epoch 3, Batch 551, loss: 0.753961 loss_age: 0.053581 loss_gender: 0.691219\n",
            "Epoch 3, Batch 601, loss: 0.754013 loss_age: 0.063163 loss_gender: 0.692106\n",
            "Epoch 3, Batch 651, loss: 0.754034 loss_age: 0.074177 loss_gender: 0.690380\n",
            "Epoch 3, Batch 701, loss: 0.753998 loss_age: 0.061783 loss_gender: 0.690050\n",
            "Epoch 3, Batch 751, loss: 0.753927 loss_age: 0.048092 loss_gender: 0.686689\n",
            "Epoch 3, Batch 801, loss: 0.753985 loss_age: 0.065599 loss_gender: 0.697816\n",
            "Epoch 3, Batch 851, loss: 0.753784 loss_age: 0.045948 loss_gender: 0.692673\n",
            "Epoch 3, Batch 901, loss: 0.753691 loss_age: 0.054331 loss_gender: 0.692107\n",
            "Epoch 3, Batch 951, loss: 0.753858 loss_age: 0.057005 loss_gender: 0.692142\n",
            "Epoch 3, Batch 1001, loss: 0.753845 loss_age: 0.045686 loss_gender: 0.694476\n",
            "Epoch 3, Batch 1051, loss: 0.753820 loss_age: 0.065299 loss_gender: 0.695612\n",
            "Epoch 3, Batch 1101, loss: 0.753774 loss_age: 0.074829 loss_gender: 0.687751\n",
            "Epoch: 3 \tTraining Loss: 0.753775 \tValidation Loss: 0.753319\n",
            "Epoch 4, Batch 1, loss: 0.748351 loss_age: 0.053879 loss_gender: 0.694472\n",
            "Epoch 4, Batch 51, loss: 0.753099 loss_age: 0.074067 loss_gender: 0.691067\n",
            "Epoch 4, Batch 101, loss: 0.754290 loss_age: 0.052759 loss_gender: 0.694158\n",
            "Epoch 4, Batch 151, loss: 0.753307 loss_age: 0.088903 loss_gender: 0.689785\n",
            "Epoch 4, Batch 201, loss: 0.753407 loss_age: 0.052767 loss_gender: 0.694451\n",
            "Epoch 4, Batch 251, loss: 0.753996 loss_age: 0.040783 loss_gender: 0.690522\n",
            "Epoch 4, Batch 301, loss: 0.754116 loss_age: 0.041214 loss_gender: 0.687198\n",
            "Epoch 4, Batch 351, loss: 0.754026 loss_age: 0.090037 loss_gender: 0.693388\n",
            "Epoch 4, Batch 401, loss: 0.753822 loss_age: 0.071131 loss_gender: 0.696025\n",
            "Epoch 4, Batch 451, loss: 0.753500 loss_age: 0.079125 loss_gender: 0.692001\n",
            "Epoch 4, Batch 501, loss: 0.753790 loss_age: 0.075387 loss_gender: 0.687840\n",
            "Epoch 4, Batch 551, loss: 0.753915 loss_age: 0.063737 loss_gender: 0.689373\n",
            "Epoch 4, Batch 601, loss: 0.753897 loss_age: 0.061242 loss_gender: 0.693495\n",
            "Epoch 4, Batch 651, loss: 0.753847 loss_age: 0.074391 loss_gender: 0.690330\n",
            "Epoch 4, Batch 701, loss: 0.753752 loss_age: 0.043501 loss_gender: 0.696386\n",
            "Epoch 4, Batch 751, loss: 0.753668 loss_age: 0.061754 loss_gender: 0.691931\n",
            "Epoch 4, Batch 801, loss: 0.753753 loss_age: 0.056276 loss_gender: 0.696696\n",
            "Epoch 4, Batch 851, loss: 0.753742 loss_age: 0.050835 loss_gender: 0.689390\n",
            "Epoch 4, Batch 901, loss: 0.753721 loss_age: 0.065870 loss_gender: 0.689566\n",
            "Epoch 4, Batch 951, loss: 0.753695 loss_age: 0.065384 loss_gender: 0.690283\n",
            "Epoch 4, Batch 1001, loss: 0.753615 loss_age: 0.059090 loss_gender: 0.682270\n",
            "Epoch 4, Batch 1051, loss: 0.753704 loss_age: 0.078125 loss_gender: 0.694314\n",
            "Epoch 4, Batch 1101, loss: 0.753709 loss_age: 0.079997 loss_gender: 0.693252\n",
            "Epoch: 4 \tTraining Loss: 0.753711 \tValidation Loss: 0.753286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiFRClLzOzpd"
      },
      "source": [
        "# Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoXffaeMTtg8"
      },
      "source": [
        "loaded_model = torch.load('model.pt')"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJzlzDHbUpim"
      },
      "source": [
        "def predict(image, max_age, device=\"cuda\", gender_threshold=0.5):\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = torch.from_numpy(image).permute(2, 0, 1).float()\n",
        "    image = image.unsqueeze(0) \n",
        "    if device == \"cuda\":\n",
        "      image = image.to(device)\n",
        "\n",
        "    predicted = loaded_model(image)\n",
        "    age = predicted[\"age\"].item() * max_age\n",
        "    prob_gender = predicted[\"gender\"].item()\n",
        "    gender = 1 if prob_gender > gender_threshold else 0\n",
        "    \n",
        "    return age, gender"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0yomO7xzzLw",
        "outputId": "4c0da6da-36ce-48ce-d485-7e2163f260bf"
      },
      "source": [
        "image_path = \"mega_age_gender/0_A14_G0.png\"\n",
        "image = cv2.imread(image_path)\n",
        "pred_age, pred_gender = predict(image, 69, 'cuda')\n",
        "print(\"pred_age: {}, pred_gender: {}\".format(pred_age, pred_gender))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pred_age: 30.283694475889206, pred_gender: 1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}